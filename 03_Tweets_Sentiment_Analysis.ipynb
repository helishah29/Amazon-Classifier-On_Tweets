{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from sklearn.metrics import precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: english_stemmer.stemWords(analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Stemmer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-26306b37088b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menglish_stemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Stemmer'"
     ]
    }
   ],
   "source": [
    "import Stemmer\n",
    "english_stemmer = Stemmer.Stemmer('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment                                               text\n",
       "0  apple  positive  Now all @Apple has to do is get swype on the i...\n",
       "1  apple  positive  @Apple will be adding more carrier support to ...\n",
       "2  apple  positive  Hilarious @youtube video - guy does a duet wit...\n",
       "3  apple  positive  @RIM you made it too easy for me to switch to ...\n",
       "4  apple  positive  I just realized that the reason I got into twi..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets = pd.read_csv(\"dataset/SandersAnalyticsTweets.csv\")\n",
    "SANTweets[\"text\"] = SANTweets[\"TweetText\"]\n",
    "SANTweets = SANTweets[[\"Topic\", \"Sentiment\", \"text\"]]\n",
    "SANTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5113, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "irrelevant    1689\n",
       "negative       572\n",
       "neutral       2333\n",
       "positive       519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets.groupby(\"Sentiment\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "apple        1142\n",
       "google       1317\n",
       "microsoft    1364\n",
       "twitter      1290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets.groupby(\"Topic\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sent(s):\n",
    "    if s == \"irrelevant\" or s == \"neutral\":\n",
    "        s = 0\n",
    "    if s == \"positive\":\n",
    "        s = 1\n",
    "    if s == \"negative\":\n",
    "        s = -1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANTweets[\"sent\"] = SANTweets[\"Sentiment\"].apply(translate_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment                                               text  sent\n",
       "0  apple  positive  Now all @Apple has to do is get swype on the i...     1\n",
       "1  apple  positive  @Apple will be adding more carrier support to ...     1\n",
       "2  apple  positive  Hilarious @youtube video - guy does a duet wit...     1\n",
       "3  apple  positive  @RIM you made it too easy for me to switch to ...     1\n",
       "4  apple  positive  I just realized that the reason I got into twi...     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>mrsshinde</td>\n",
       "      <td>RT @mrsshinde: @SamsungMobile @Moto @oneplus @...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>olutobi_og</td>\n",
       "      <td>@SamsungMobile kindly include play next in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>themobileindian</td>\n",
       "      <td>@SamsungMobile has started rolling out the And...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>sobakhani</td>\n",
       "      <td>@SamsungMobile how to find lost Samsung note 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Imchetan_p</td>\n",
       "      <td>@SamsungMobile @SamsungIndia @Samsung I must s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang user_screen_name                                               text  \\\n",
       "0   en        mrsshinde  RT @mrsshinde: @SamsungMobile @Moto @oneplus @...   \n",
       "1   en       olutobi_og  @SamsungMobile kindly include play next in the...   \n",
       "2   en  themobileindian  @SamsungMobile has started rolling out the And...   \n",
       "3   en        sobakhani  @SamsungMobile how to find lost Samsung note 1...   \n",
       "4   en       Imchetan_p  @SamsungMobile @SamsungIndia @Samsung I must s...   \n",
       "\n",
       "   sent  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4    -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMTweets = pd.read_csv(\"dataset/SamsungTweetsSent.csv\")\n",
    "SMTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent\n",
       "-1    132\n",
       " 0    138\n",
       " 1     19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMTweets.groupby(\"sent\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BStoly @mashable Brenda, blockbuster story! \\...</td>\n",
       "      <td>en</td>\n",
       "      <td>ScanMyPhotos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could #CES2020 have been the event that spread...</td>\n",
       "      <td>en</td>\n",
       "      <td>dsilverman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Segway’s S-Pod makes WALL-E’s hoverchair a re...</td>\n",
       "      <td>en</td>\n",
       "      <td>v_shakthi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News coming out that #CES2020 may have been th...</td>\n",
       "      <td>en</td>\n",
       "      <td>dc_colombo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you missed it, check this story about the #...</td>\n",
       "      <td>en</td>\n",
       "      <td>nycbat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang      username\n",
       "0  @BStoly @mashable Brenda, blockbuster story! \\...   en  ScanMyPhotos\n",
       "1  Could #CES2020 have been the event that spread...   en    dsilverman\n",
       "2  #Segway’s S-Pod makes WALL-E’s hoverchair a re...   en     v_shakthi\n",
       "3  News coming out that #CES2020 may have been th...   en    dc_colombo\n",
       "4  If you missed it, check this story about the #...   en        nycbat"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CESTweets = pd.read_csv(\"dataset/ces2020_tweets_full_text.csv\")\n",
    "CESTweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries and preprocessing function from previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_repl = {\n",
    "    # positive emoticons\n",
    "    r\":-?d+\": \" good \", r\":[- ]?\\)+\": \" good \", r\";-?\\)+\": \" good \",\n",
    "    r\"\\(+-?:\": \" good \", r\"=\\)+\" : \" good \", r\"\\b<3\\b\" : \" good \",    \n",
    "    # negative emoticons\n",
    "    r\"[\\s\\r\\t\\n]+:/+\": \" bad \", r\":\\\\+\": \" bad \", r\"[\\s\\r\\t\\n]+\\)-?:\": \" bad \",\n",
    "    r\":-?\\(+\": \" bad \", r\"[\\s\\t\\r\\n]+d+-?:\": \" bad \"\n",
    "}\n",
    "\n",
    "contracted_repl = {\n",
    "    # casi particolari\n",
    "    r\"won\\'t\" : \"will not\", r\"won\\'\" : \"will not\", r\"can\\'t\": \"can not\", r\"shan\\'t\": \"shall not\",\n",
    "    r\"shan\\'\": \"shall not\", r\"ain\\'t\": \"is not\", r\"ain\\'\": \"is not\",\n",
    "    # casi generali\n",
    "    r\"n\\'t\": \" not\", r\"\\'t\": \" not\", r\"n\\'\": \" not\", r\"\\'s\": \" is\", r\"\\'ve\": \" have\", \n",
    "    r\"\\'re\": \" are\", \n",
    "    r\"\\'ll\": \" will\", r\"\\'d\": \" would\",\n",
    "}\n",
    "\n",
    "with open('dataset/slang_subset_manual.json', 'r') as fid:\n",
    "    slang_repl = json.load(fid)\n",
    "    \n",
    "def preprocess(sent, translate_slang = True):\n",
    "    \n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'^<div id=\"video.*>&nbsp;', '', sent) # Video-review part\n",
    "    sent = re.sub('https?://[A-Za-z0-9./]+', '', sent) # URLs\n",
    "    \n",
    "    for k in emoticon_repl:\n",
    "        sent = re.sub(k, emoticon_repl[k], sent)\n",
    "\n",
    "    if translate_slang:\n",
    "        for k in slang_repl:\n",
    "            sent = re.sub(r\"\\b\"+k+r\"\\b\", slang_repl[k], sent)\n",
    "        \n",
    "    for k in contracted_repl:\n",
    "        sent = re.sub(k, contracted_repl[k], sent)\n",
    "    \n",
    "    sent = re.sub('[/]+', ' ', sent) # word1/word2 to word1 word2\n",
    "    sent = re.sub('[^A-Za-z0-9-_ ]+', '', sent)\n",
    "    sent = re.sub('\\b\\d+\\b', '', sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for preprocessing tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweets_df):\n",
    "    from spellchecker import SpellChecker\n",
    "    spell = SpellChecker(distance=1)\n",
    "    \n",
    "    tweets_df[\"textPreprocessed\"] = tweets_df.text\n",
    "    tweets_df[\"textPreprocessed\"] =  tweets_df[\"textPreprocessed\"].str.replace(\"@\\w+\", \"\") # remove AT's\n",
    "    tweets_df[\"textPreprocessed\"] = tweets_df[\"textPreprocessed\"].str.replace(\"^(RT)+\", \"\") # Remove RT at beginning of retweets\n",
    "    \n",
    "    # Add stuff probably\n",
    "    \n",
    "    tweets_df[\"textPreprocessed\"] = tweets_df[\"textPreprocessed\"].apply(preprocess)\n",
    "    tweets_df[\"textPreprocessed\"] = tweets_df[\"textPreprocessed\"].apply(\n",
    "        lambda x : \" \".join([spell.correction(el) for el in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this function to the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>username</th>\n",
       "      <th>textPreprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BStoly @mashable Brenda, blockbuster story! \\...</td>\n",
       "      <td>en</td>\n",
       "      <td>ScanMyPhotos</td>\n",
       "      <td>brenda blockbuster story myself and thousands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could #CES2020 have been the event that spread...</td>\n",
       "      <td>en</td>\n",
       "      <td>dsilverman</td>\n",
       "      <td>could ces2020 have been the event that spread ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Segway’s S-Pod makes WALL-E’s hoverchair a re...</td>\n",
       "      <td>en</td>\n",
       "      <td>v_shakthi</td>\n",
       "      <td>segways s-pod makes wall-es hoverchair a reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News coming out that #CES2020 may have been th...</td>\n",
       "      <td>en</td>\n",
       "      <td>dc_colombo</td>\n",
       "      <td>news coming out that ces2020 may have been the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you missed it, check this story about the #...</td>\n",
       "      <td>en</td>\n",
       "      <td>nycbat</td>\n",
       "      <td>if you missed it check this story about the ce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang      username  \\\n",
       "0  @BStoly @mashable Brenda, blockbuster story! \\...   en  ScanMyPhotos   \n",
       "1  Could #CES2020 have been the event that spread...   en    dsilverman   \n",
       "2  #Segway’s S-Pod makes WALL-E’s hoverchair a re...   en     v_shakthi   \n",
       "3  News coming out that #CES2020 may have been th...   en    dc_colombo   \n",
       "4  If you missed it, check this story about the #...   en        nycbat   \n",
       "\n",
       "                                    textPreprocessed  \n",
       "0  brenda blockbuster story myself and thousands ...  \n",
       "1  could ces2020 have been the event that spread ...  \n",
       "2  segways s-pod makes wall-es hoverchair a reali...  \n",
       "3  news coming out that ces2020 may have been the...  \n",
       "4  if you missed it check this story about the ce...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweets(CESTweets)\n",
    "CESTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>sent</th>\n",
       "      <th>textPreprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>mrsshinde</td>\n",
       "      <td>RT @mrsshinde: @SamsungMobile @Moto @oneplus @...</td>\n",
       "      <td>0</td>\n",
       "      <td>we must work to save safeguard humans from mob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>olutobi_og</td>\n",
       "      <td>@SamsungMobile kindly include play next in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>kindly include play next in the next samsungmu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>themobileindian</td>\n",
       "      <td>@SamsungMobile has started rolling out the And...</td>\n",
       "      <td>0</td>\n",
       "      <td>has started rolling out the android 10 update ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>sobakhani</td>\n",
       "      <td>@SamsungMobile how to find lost Samsung note 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>how to find lost samsung note 10 plus in pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Imchetan_p</td>\n",
       "      <td>@SamsungMobile @SamsungIndia @Samsung I must s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>i must say that your sales services really suc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang user_screen_name                                               text  \\\n",
       "0   en        mrsshinde  RT @mrsshinde: @SamsungMobile @Moto @oneplus @...   \n",
       "1   en       olutobi_og  @SamsungMobile kindly include play next in the...   \n",
       "2   en  themobileindian  @SamsungMobile has started rolling out the And...   \n",
       "3   en        sobakhani  @SamsungMobile how to find lost Samsung note 1...   \n",
       "4   en       Imchetan_p  @SamsungMobile @SamsungIndia @Samsung I must s...   \n",
       "\n",
       "   sent                                   textPreprocessed  \n",
       "0     0  we must work to save safeguard humans from mob...  \n",
       "1     0  kindly include play next in the next samsungmu...  \n",
       "2     0  has started rolling out the android 10 update ...  \n",
       "3     0  how to find lost samsung note 10 plus in pakistan  \n",
       "4    -1  i must say that your sales services really suc...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweets(SMTweets)\n",
    "SMTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>sent</th>\n",
       "      <th>textPreprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "      <td>1</td>\n",
       "      <td>now all has to do is get swipe on the phone an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>will be adding more carrier support to the pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>hilarious video - guy does a duet with is sir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>you made it too easy for me to switch to phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "      <td>1</td>\n",
       "      <td>i just realized that the reason i got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment                                               text  sent  \\\n",
       "0  apple  positive  Now all @Apple has to do is get swype on the i...     1   \n",
       "1  apple  positive  @Apple will be adding more carrier support to ...     1   \n",
       "2  apple  positive  Hilarious @youtube video - guy does a duet wit...     1   \n",
       "3  apple  positive  @RIM you made it too easy for me to switch to ...     1   \n",
       "4  apple  positive  I just realized that the reason I got into twi...     1   \n",
       "\n",
       "                                    textPreprocessed  \n",
       "0  now all has to do is get swipe on the phone an...  \n",
       "1  will be adding more carrier support to the pho...  \n",
       "2  hilarious video - guy does a duet with is sir ...  \n",
       "3  you made it too easy for me to switch to phone...  \n",
       "4  i just realized that the reason i got into twi...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweets(SANTweets)\n",
    "SANTweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiwordnet Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/helishah/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/helishah/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SWNClassifier takes in input the pre-processed tweets and  works as follows:\n",
    "\n",
    "\n",
    "- Each tweet is split in tokens using nltk's tokenizer;\n",
    "- A *Part of Speech* tag is assigned to each token with nltk's `pos_tag` function;\n",
    "- Each tag is translated to a SentiWordNet tag;\n",
    "- Each token/tag pair is assigned the positivity and negativity score defined by SentiWordNet;\n",
    "- The positivity and negativity score of a tweet is computed as the sum of positivity and negativity scores of the constituting tokens;\n",
    "- If both positivity and negativity scores are 0, the tweet is labelled as neutral. If the positivity score is greater than the negativity score, the tweet is labelled as positive, and negative otherwise.\n",
    "\n",
    "The function returns, for a list of tweets:\n",
    "\n",
    "- Their tokens and their tags\n",
    "- Their positivity score\n",
    "- Their negativity score\n",
    "- Their sentiment score (-1 for negative, 0 for neutral, 1 for positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SWNClassifier(X):\n",
    "    # Adapted from https://towardsdatascience.com/sentiment-analysis-on-swachh-bharat-using-twitter-216369cfa534\n",
    "    lem = WordNetLemmatizer()\n",
    "    pstem = PorterStemmer()\n",
    "    X_tagged = []\n",
    "    li_swn=[]\n",
    "    li_swn_pos=[]\n",
    "    li_swn_neg=[]\n",
    "    missing_words=[]\n",
    "    for i in range(len(X)):\n",
    "        text = X[i]\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tagged_sent = nltk.tag.pos_tag(tokens)\n",
    "        store_it = [(word, nltk.tag.map_tag('en-ptb', 'universal', tag)) for word, tag in tagged_sent]\n",
    "        X_tagged.append(store_it)\n",
    "        #print(\"Tagged Parts of Speech:\",store_it)\n",
    "\n",
    "        pos_total=0\n",
    "        neg_total=0\n",
    "        for word,tag in store_it:\n",
    "            # print(tag)\n",
    "            if(tag=='NOUN'):\n",
    "                tag='n'\n",
    "            elif(tag=='VERB'):\n",
    "                tag='v'\n",
    "            elif(tag=='ADJ'):\n",
    "                tag='a'\n",
    "            elif(tag=='ADV'):\n",
    "                tag = 'r'\n",
    "            else:\n",
    "                tag='nothing'\n",
    "\n",
    "                \n",
    "            if(tag!='nothing'):\n",
    "                concat = word+'.'+tag+'.01'\n",
    "                try:\n",
    "                    this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                    this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                    # print(word,tag,':',this_word_pos,this_word_neg)\n",
    "                except Exception as e:\n",
    "                    wor = lem.lemmatize(word)\n",
    "                    concat = wor+'.'+tag+'.01'\n",
    "                    # Checking if there's a possiblity of lemmatized word be accepted into SWN corpus\n",
    "                    try:\n",
    "                        this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                        this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                    except Exception as e:\n",
    "                        wor = pstem.stem(word)\n",
    "                        concat = wor+'.'+tag+'.01'\n",
    "                        # Checking if there's a possiblity of lemmatized word be accepted\n",
    "                        try:\n",
    "                            this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                            this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                        except:\n",
    "                            missing_words.append(word)\n",
    "                            continue\n",
    "                pos_total+=this_word_pos\n",
    "                neg_total+=this_word_neg\n",
    "        li_swn_pos.append(pos_total)\n",
    "        li_swn_neg.append(neg_total)\n",
    "\n",
    "        if(pos_total!=0 or neg_total!=0):\n",
    "            if(pos_total>neg_total):\n",
    "                li_swn.append(1)\n",
    "            else:\n",
    "                li_swn.append(-1)\n",
    "        else:\n",
    "            li_swn.append(0)\n",
    "            \n",
    "    return X_tagged, li_swn_pos, li_swn_neg, li_swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_test, predictions):\n",
    "\n",
    "    prec = precision_score(y_test, predictions) # Precision\n",
    "    rec = recall_score(y_test, predictions) # Recall\n",
    "    f1 = f1_score(y_test, predictions) # F1\n",
    "    f2 = fbeta_score(y_test, predictions, 2) # F2\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    scores_strings = [\"Test Precision\",\n",
    "                      \"Test Recall\", \"F1\", \"F2\"]\n",
    "    \n",
    "    scores = [prec, rec, f1, f2]\n",
    "    \n",
    "    print((\"{:20s} {:.5f}\\n\"*4)[:-1].format(*itertools.chain(*zip(scores_strings, scores))))\n",
    "    \n",
    "    print(classification_report(y_test, predictions, digits=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the SWNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the SWNClassifier on SanTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the positive/negative/neutral labels assigned by the SWNClassifier with the original labels assigned to SANTweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.19 s, sys: 330 ms, total: 9.52 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SANTweets_tagged, SANTweets_SWN_POS, SANTweets_SWN_NEG, SANTweets_SWN_SENT = SWNClassifier(SANTweets.textPreprocessed.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANTweets_SENT = SANTweets.sent.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on positive/negative/neutral labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1    0.23529   0.54545   0.32877       572\n",
      "           0    0.93148   0.37519   0.53492      4022\n",
      "           1    0.16844   0.70328   0.27178       519\n",
      "\n",
      "   micro avg    0.42754   0.42754   0.42754      5113\n",
      "   macro avg    0.44507   0.54131   0.37849      5113\n",
      "weighted avg    0.77614   0.42754   0.48514      5113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(SANTweets_SENT, SANTweets_SWN_SENT, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on Neutral/Sentiment labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.93148\n",
      "Test Recall          0.37519\n",
      "F1                   0.53492\n",
      "F2                   0.42608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.28056   0.89826   0.42757      1091\n",
      "        True    0.93148   0.37519   0.53492      4022\n",
      "\n",
      "   micro avg    0.48680   0.48680   0.48680      5113\n",
      "   macro avg    0.60602   0.63672   0.48125      5113\n",
      "weighted avg    0.79259   0.48680   0.51201      5113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(SANTweets_SENT==0, np.array(SANTweets_SWN_SENT)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the SWNClassifier on SMTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the positive/negative/neutral labels assigned by the SWNClassifier with the manual labels assigned to SMTweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 535 ms, sys: 12.8 ms, total: 547 ms\n",
      "Wall time: 564 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SMTweets_tagged, SMTweets_SWN_POS, SMTweets_SWN_NEG, SMTweets_SWN_SENT = SWNClassifier(SMTweets.textPreprocessed.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMTweets_MANUAL_SENT = SMTweets.sent.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on positive/negative/neutral labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1    0.66418   0.67424   0.66917       132\n",
      "           0    0.75000   0.15217   0.25301       138\n",
      "           1    0.08661   0.57895   0.15068        19\n",
      "\n",
      "   micro avg    0.41869   0.41869   0.41869       289\n",
      "   macro avg    0.50026   0.46845   0.35762       289\n",
      "weighted avg    0.66719   0.41869   0.43637       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(SMTweets_MANUAL_SENT, np.array(SMTweets_SWN_SENT), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on Neutral/Sentiment labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.75000\n",
      "Test Recall          0.15217\n",
      "F1                   0.25301\n",
      "F2                   0.18103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.55172   0.95364   0.69903       151\n",
      "        True    0.75000   0.15217   0.25301       138\n",
      "\n",
      "   micro avg    0.57093   0.57093   0.57093       289\n",
      "   macro avg    0.65086   0.55291   0.47602       289\n",
      "weighted avg    0.64640   0.57093   0.48605       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(SMTweets_MANUAL_SENT == 0, np.array(SMTweets_SWN_SENT)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Multinomial Naive Bayes Classifier from previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load joblib files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('joblib_data/tfidf_vect_nostemmer.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('joblib_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = load('joblib_data/tfidf_vect_nostemmer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('joblib_data/clf_nb_nostemmer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating MNB Classifier on Samsung Mobile Tweet Replies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate our classifier on the SMTweets. Because our classifier only outputs positive/negative, we have to filter out neutral tweets. Hence, we take into account:\n",
    "\n",
    "- SMTweets manually labelled as positive/negative;\n",
    "- SMTweets labelled as positive/negative by the SWNClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMTweets manually labelled as positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMTweets_MANUAL_POS_NEG = SMTweets[SMTweets.sent != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMTweets_MANUAL_POS_NEG_x = SMTweets_MANUAL_POS_NEG.textPreprocessed.values\n",
    "SMTweets_MANUAL_POS_NEG_y = SMTweets_MANUAL_POS_NEG.sent.values == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual labels: 139 negative, 19 positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([132,  19]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(SMTweets_MANUAL_POS_NEG_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<151x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2393 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMTweets_MANUAL_POS_NEG_x_vect = vectorizer.transform(SMTweets_MANUAL_POS_NEG_x)\n",
    "SMTweets_MANUAL_POS_NEG_x_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the MNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 ms, sys: 1.25 ms, total: 2.69 ms\n",
      "Wall time: 1.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = clf.predict(SMTweets_MANUAL_POS_NEG_x_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([102,  49]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB predictions against the manual labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.12245\n",
      "Test Recall          0.31579\n",
      "F1                   0.17647\n",
      "F2                   0.24000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.87255   0.67424   0.76068       132\n",
      "        True    0.12245   0.31579   0.17647        19\n",
      "\n",
      "   micro avg    0.62914   0.62914   0.62914       151\n",
      "   macro avg    0.49750   0.49502   0.46858       151\n",
      "weighted avg    0.77817   0.62914   0.68717       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(SMTweets_MANUAL_POS_NEG_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMTweets labelled as positive or negative by the SWNClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMTweets_SWN_SENT = np.array(SMTweets_SWN_SENT)\n",
    "SMTweets_SWN_POS_NEG_x = SMTweets.textPreprocessed.values[SMTweets_SWN_SENT != 0]\n",
    "SMTweets_SWN_POS_NEG_y = SMTweets_SWN_SENT[SMTweets_SWN_SENT != 0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWN Labels: 134 negative, 127 positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([134, 127]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(SMTweets_SWN_POS_NEG_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<261x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3739 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMTweets_SWN_POS_NEG_x_vect = vectorizer.transform(SMTweets_SWN_POS_NEG_x)\n",
    "SMTweets_SWN_POS_NEG_x_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the MNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 ms, sys: 572 µs, total: 1.94 ms\n",
      "Wall time: 925 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = clf.predict(SMTweets_SWN_POS_NEG_x_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([190,  71]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB predictions against the SWN labels on SMTweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.45070\n",
      "Test Recall          0.25197\n",
      "F1                   0.32323\n",
      "F2                   0.27634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.50000   0.70896   0.58642       134\n",
      "        True    0.45070   0.25197   0.32323       127\n",
      "\n",
      "   micro avg    0.48659   0.48659   0.48659       261\n",
      "   macro avg    0.47535   0.48046   0.45483       261\n",
      "weighted avg    0.47601   0.48659   0.45836       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(SMTweets_SWN_POS_NEG_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating MNB Classifier on Sanders Analytics Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate our classifier on the SANTweets. Because our classifier only outputs positive/negative, we have to filter out neutral tweets. Hence, we take into account:\n",
    "\n",
    "- SANTweets originally labelled as positive/negative;\n",
    "- SANTweets labelled as positive/negative by the SWNClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANTweets labelled as positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANTweets_SENT = SANTweets.sent.values\n",
    "SANTweets_POS_NEG_x = SANTweets.textPreprocessed.values[SANTweets_SENT != 0]\n",
    "SANTweets_POS_NEG_y = SANTweets_SENT[SANTweets_SENT != 0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original labels: 572 negative, 519 positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([572, 519]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(SANTweets_POS_NEG_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1091x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets_POS_NEG_x_vect = vectorizer.transform(SANTweets_POS_NEG_x)\n",
    "SANTweets_POS_NEG_x_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the MNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 ms, sys: 670 µs, total: 2.06 ms\n",
      "Wall time: 934 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = clf.predict(SANTweets_POS_NEG_x_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([690, 401]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB predictions against the original SANTweets labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.48878\n",
      "Test Recall          0.37765\n",
      "F1                   0.42609\n",
      "F2                   0.39564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.53188   0.64161   0.58162       572\n",
      "        True    0.48878   0.37765   0.42609       519\n",
      "\n",
      "   micro avg    0.51604   0.51604   0.51604      1091\n",
      "   macro avg    0.51033   0.50963   0.50385      1091\n",
      "weighted avg    0.51138   0.51604   0.50763      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(SANTweets_POS_NEG_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANTweets labelled as positive or negative by the SWNClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANTweets_SWN_SENT = np.array(SANTweets_SWN_SENT)\n",
    "SANTweets_SWN_POS_NEG_x = SANTweets.textPreprocessed.values[SANTweets_SWN_SENT != 0]\n",
    "SANTweets_SWN_POS_NEG_y = SANTweets_SWN_SENT[SANTweets_SWN_SENT != 0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWN SANTweets Labels: 1326 negative, 2167 positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([1326, 2167]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(SANTweets_SWN_POS_NEG_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3493x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27226 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANTweets_SWN_POS_NEG_x_vect = vectorizer.transform(SANTweets_SWN_POS_NEG_x)\n",
    "SANTweets_SWN_POS_NEG_x_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the MNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 ms, sys: 898 µs, total: 2.63 ms\n",
      "Wall time: 1.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = clf.predict(SANTweets_SWN_POS_NEG_x_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([2226, 1267]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB predictions against the SWN labels on SANTweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.63931\n",
      "Test Recall          0.37379\n",
      "F1                   0.47175\n",
      "F2                   0.40765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.39039   0.65535   0.48930      1326\n",
      "        True    0.63931   0.37379   0.47175      2167\n",
      "\n",
      "   micro avg    0.48068   0.48068   0.48068      3493\n",
      "   macro avg    0.51485   0.51457   0.48053      3493\n",
      "weighted avg    0.54481   0.48068   0.47841      3493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(SANTweets_SWN_POS_NEG_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating MNB Classifier on CESTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because CESTweets do not have any label, we can only rely on the SWNClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CESTweets_tagged, CESTweets_SWN_POS, CESTweets_SWN_NEG, CESTweets_SWN_SENT = SWNClassifier(CESTweets.textPreprocessed.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CESTweets labelled as positive or negative by the SWNClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "CESTweets_SWN_SENT = np.array(CESTweets_SWN_SENT)\n",
    "CESTweets_SWN_POS_NEG_x = CESTweets.textPreprocessed.values[CESTweets_SWN_SENT != 0]\n",
    "CESTweets_SWN_POS_NEG_y = CESTweets_SWN_SENT[CESTweets_SWN_SENT != 0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWN CESTweets Labels: 465 negative, 1229 positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([24, 52]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(CESTweets_SWN_POS_NEG_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<76x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CESTweets_SWN_POS_NEG_x_vect = vectorizer.transform(CESTweets_SWN_POS_NEG_x)\n",
    "CESTweets_SWN_POS_NEG_x_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the MNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 ms, sys: 699 µs, total: 2.12 ms\n",
      "Wall time: 913 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = clf.predict(CESTweets_SWN_POS_NEG_x_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([47, 29]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB predictions against the SWN labels on SMTweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision       0.75862\n",
      "Test Recall          0.42308\n",
      "F1                   0.54321\n",
      "F2                   0.46414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.36170   0.70833   0.47887        24\n",
      "        True    0.75862   0.42308   0.54321        52\n",
      "\n",
      "   micro avg    0.51316   0.51316   0.51316        76\n",
      "   macro avg    0.56016   0.56571   0.51104        76\n",
      "weighted avg    0.63328   0.51316   0.52289        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores(CESTweets_SWN_POS_NEG_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
